<h1>Тестовое задание на Django для bibinet</h1>
<p> Необходимо создать 2 сервиса с отдачей данных в JSON формате, на Django и FastAPI.  
Базу используем PostgreSQL. 
Django >= 3.12 
Сторонние библиотеки не используем, такие как Django REST framework. Делаем тем что идет из 
коробки с Django 
Создаем модели базы данных: 
• mark (id, name, producer_country_name, is_visible) 
• model (id, name, mark_id, is_visible) 
• part (id, name, mark_id, model_id, price, json_data, is_visible) 
Заполнить таблицы mark model по 5 записей будет достаточно. 
Написать скрипт для заполнения таблицы part через модель ORM, рандомно 10_000 записей. 
Наименование запчасти можно заполнять из массива, 5 записей хватит. json_data словарь в 
коротом могут быть ключи (color, is_new_part, count) так же рандомно заполнять от всех ключей 
до пустого словаря. 
Модели оптимизировать и добавить индексы для поиска, варианты запросов для оптимизации: 
• Название запчасти, марка автомобиля, цвет автомобиля (color), показывать 
запчасть (is_visible) 
• Страна производителя (producer_country_name), новая запчасть (is_new_part), 
показывать запчасть (is_visible) 
Добавляем пути для вывода марок и моделей /mark/ и /model/ 
Создаем поиск по запчастям 

  
Выводим по 10 записей в результатах (через page выводим следующие страницы) 
response - список с результатом поиска (по 10) 
count - количество всех найденных запчастей 
summ – сумма всех найденных запчастей по параметру price 
  
FastAPI 
Сделать только поиск запчастей (такой же как на Django), но все запросы пишем на чистом SQL. 
  
 Итог 
Написать команды для запуска в боевом режиме, для каждого из сервисов. Веб сервер 
используем Nginx. Настроить запуск так, чтобы максимально утилизировать процессор. 
Показать готовый вариант или описать как можно было бы обновлять проект без потери 
пользовательских соединений.  
Все разворачивать можно по-разному, просто через Python системный, или же через Docker. 
Так же было бы не лишним проверить по производительности оба поиска запчастей через 
утилиту wrk или siege (по возможности запускать с другого ПК, в локальной сети) и сделать 
сравнение что быстрее, и по сколько запросов обрабатывается, через htop можно так же 
проверить какая нагрузка. 
  
Создаем Git репозиторий, и делаем коммиты почаще для каждой новой логики, все можно в 
одном репозитории делать. 
</p>

<h2>ИНСТРУКЦИЯ ПО ЗАПУСКУ ПРОЕКТА:</h2>
<p>Оба сервиса запускаем через команду:</p>
  <code>docker-compose -f docker-compose.prod.yml up -d</code> <p>для прода</p> 
  <code>docker-compose -f docker-compose.dev.yml up -d </code> <p>для запуска в режиме разработки.</p>
<h3>Бесшовный деплой можно настроить с помощью docker swarm и настроенным для этого docker-compose файлом, который будет иметь примерно такой вид:</h3>
<code>deploy:
      placement:
        constraints:
          - "node.labels.TAG==stage"
      replicas: 1
      update_config:
        parallelism: 1
        order: start-first
        failure_action: rollback
        delay: 10s
      rollback_config:
        parallelism: 0
        order: stop-first
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
    healthcheck:
      test: curl -sS http://127.0.0.1:4003/ptm/api/healthcheck || echo 1
      interval: 30s
      timeout: 3s
      retries: 12
</code>
<p>И пример комманды докер сварм:</p>
<code>docker pull docker-registry.ru:5000/ptm:stage;
docker service update --image docker-registry.ru:5000/ptm:stage stage;</code>
<p>Из-за нехватки времени реализовать это и сравнение разных поисков в проекте не успел.</p>
